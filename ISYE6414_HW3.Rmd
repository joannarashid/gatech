---
title: "HW3 Peer Assessment"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Background

The fishing industry uses numerous measurements to describe a specific fish.  Our goal is to predict the weight of a fish based on a number of these measurements and determine if any of these measurements are insignificant in determining the weigh of a product.  See below for the description of these measurements.  

## Data Description

The data consists of the following variables:

1. **Weight**: weight of fish in g (numerical)
2. **Species**: species name of fish (categorical)
3. **Body.Height**: height of body of fish in cm (numerical)
4. **Total.Length**: length of fish from mouth to tail in cm (numerical)
5. **Diagonal.Length**: length of diagonal of main body of fish in cm (numerical)
6. **Height**: height of head of fish in cm (numerical)
7. **Width**: width of head of fish in cm (numerical)


## Read the data

```{r}
# Import library you may need
library(car)
# Read the data set
fishfull = read.csv("~/Documents/R/Fish.csv",header=T, fileEncoding = 'UTF-8-BOM')
row.cnt = nrow(fishfull)
# Split the data into training and testing sets
fishtest = fishfull[(row.cnt-9):row.cnt,]
fish = fishfull[1:(row.cnt-10),]
```

*Please use fish as your data set for the following questions unless otherwise stated.*

# Question 1: Exploratory Data Analysis [8 points]

**(a) Create a box plot comparing the response variable, *Weight*, across the multiple *species*.  Based on this box plot, does there appear to be a relationship between the predictor and the response?**

```{r}
library(ggplot2)
ggplot(fish, aes(x=Species, y=Weight, color=Species)) +
  geom_boxplot()
```

Yes, there does appear to be a realtionship between sepcies of fish and weight of the fish.

**(b) Create scatterplots of the response, *Weight*, against each quantitative predictor, namely **Body.Height**, **Total.Length**, **Diagonal.Length**, **Height**, and **Width**.  Describe the general trend of each plot.  Are there any potential outliers?**

```{r}
library(gridExtra)

bh <- ggplot(fish, aes(x=Body.Height, y=Weight))+
         geom_point()+
         geom_smooth(method=lm)

tl <- ggplot(fish, aes(x=Total.Length, y=Weight))+
         geom_point()+
         geom_smooth(method=lm)

dl <-ggplot(fish, aes(x=Diagonal.Length, y=Weight))+
         geom_point()+
         geom_smooth(method=lm)

h <- ggplot(fish, aes(x=Height, y=Weight))+
         geom_point()+
         geom_smooth(method=lm)

w <- ggplot(fish, aes(x=Width, y=Weight))+
         geom_point()+
         geom_smooth(method=lm)

grid.arrange(bh,tl, dl, h, w, nrow = 2)

```
All of these predictors are positively correlated with the response variable, Weight. It seems there is at least one outlier that can be visualized in each scatter plot.  All variables, especially Weight, appear to have increasing variance suggesting heteroskedascisity.

**(c) Display the correlations between each of the quantitative variables.  Interpret the correlations in the context of the relationships of the predictors to the response and in the context of multicollinearity.**

```{r}
library(GGally)
library(corrplot)

ggpairs(fish, title="Correlogram") 
```
It seems that all of the predictor variables have a statistically significant positive correlation with the response variable. However, it does seem that multiple variables are correlated with one another. For example, strong multicollinarity likely exists between Total.Length and Body.Height.

**(d) Based on this exploratory analysis, is it reasonable to assume a multiple linear regression model for the relationship between *Weight* and the predictor variables?**

Yes, linear regression is a good approach for this data set.  However, variable trasnofrmation will be required to address mulicollinarity between variables and to address heteroskedacisity of variable.  Adding the catagorical variable, 'Species' should help the model as well.

# Question 2: Fitting the Multiple Linear Regression Model [8 points]

*Create the full model without transforming the response variable or predicting variables using the fish data set.  Do not use fishtest*

**(a) Build a multiple linear regression model, called model1, using the response and all predictors.  Display the summary table of the model.**

```{r}
model1 <- lm(Weight~., data=fish)
summary(model1)
```

**(b) Is the overall regression significant at an $\alpha$ level of 0.01? Explain.**

Yes, this model is significant at a level of >99%, becaus ehte p-value of the f-stat is nearly 0.


**(c) What is the coefficient estimate for *Body.Height*? Interpret this coefficient.**

-176.87 is the coefficient for Body.Height.  This means that in this model, the effect of Body.Height on Weight is marginally negative when all variables are held constant- that is that for a one unit increase in Body.Height, this is a marginal decrease of 176.87g in Weight.

**(d) What is the coefficient estimate for the *Species* category Parkki? Interpret this coefficient.**

79.34 is the coefficient for Species = Parkki.  This means that is the species is Parkki, the Weight is of the fish is marginally greater.  So if a fish is of the Parkki species, holding all other variables constant, it will weigh 79.34g more.

# Question 3: Checking for Outliers and Multicollinearity [6 points]

**(a) Create a plot for the Cook's Distances. Using a threshold Cook's Distance of 1, identify the row numbers of any outliers.**

```{r}
plot(cooks.distance(model1))
abline(h=1, col="blue")
```

It looks like there is one outlier that is far outside the threshold value of 1.

**(b) Remove the outlier(s) from the data set and create a new model, called model2, using all predictors with *Weight* as the response.  Display the summary of this model.**

```{r}
which(cooks.distance(model1)>1)
```
```{r}
model2 <- lm(Weight~., subset = (-30), data = fish) #removeing outlier at index 30
summary(model2)
```


**(c) Display the VIF of each predictor for model2. Using a VIF threshold of max(10, 1/(1-$R^2$) what conclusions can you draw?**

```{r}
vif(model2)

r2 <- summary(model2)$r.squared

print("VIF threshold")
max(10,1/(1-r2))
```
All of the variables have a VIF above the threshold value of 16.25583.  There is significant mutlicolliniarity among all the predictive variables. 

# Question 4: Checking Model Assumptions [6 points]

*Please use the cleaned data set, which have the outlier(s) removed, and model2 for answering the following questions.*

**(a) Create scatterplots of the standardized residuals of model2 versus each quantitative predictor. Does the linearity assumption appear to hold for all predictors?**

```{r}
fish2 <- fish[-30,] #removing outlier

res <- resid(model2)

bh <- ggplot(fish2, aes(x=Body.Height, y=res))+
         geom_point()+
         geom_smooth(method=loess)

tl <- ggplot(fish2, aes(x=Total.Length, y=res))+
         geom_point()+
         geom_smooth(method=loess)

dl <-ggplot(fish2, aes(x=Diagonal.Length, y=res))+
         geom_point()+
         geom_smooth(method=loess)

h <- ggplot(fish2, aes(x=Height, y=res))+
         geom_point()+
         geom_smooth(method=loess)

w <- ggplot(fish2, aes(x=Width, y=res))+
         geom_point()+
         geom_smooth(method=loess)

grid.arrange(bh,tl, dl, h, w, nrow = 2)

```
The linearity assumption does not appear to hold for any of the above quantitative predictors. The trend line follows a U-shape or near U-shape for all predicting variables and all have values below zero.  

**(b) Create a scatter plot of the standardized residuals of model2 versus the fitted values of model2.  Does the constant variance assumption appear to hold?  Do the errors appear uncorrelated?**

```{r}
plot(model2, which=1)
```

The residuals do not appear random in the above illustrating that the constant variance assumption does not hold. The residuals following a U-shape which suggests that the linearity assumption does not hold. Howver, errors are not clustered.

**(c) Create a histogram and normal QQ plot for the standardized residuals. What conclusions can you draw from these plots?**

```{r}
hist(model2$residuals, col ="blue")

plot(model2, which =2,  col ="blue")
```
The histogram of residuals show the are left skewed and the QQ plot has a heavy right tail.  This confirms that the normality assumption does not hold indicating that the response variable should be transformed.


# Question 5: Partial F Test [6 points]

**(a) Build a third multiple linear regression model using the cleaned data set without the outlier(s), called model3, using only *Species* and *Total.Length* as predicting variables and *Weight* as the response.  Display the summary table of the model3.**

```{r}
model3 <- lm(Weight~ Species+ Total.Length, data = fish2)
summary(model3)
```

**(b) Conduct a partial F-test comparing model3 with model2. What can you conclude using an $\alpha$ level of 0.01?**

```{r}
anova(model2, model3)
```
At a level of >99% significance, we cannot reject the null hypothesis that at least one coefficient is equal to 0. The p-value on the f-stat is .14 which is far too large to reject the null hypothesis.

# Question 6: Reduced Model Residual Analysis and Multicollinearity Test [7 points]

**(a) Conduct a multicollinearity test on model3.  Comment on the multicollinearity in model3.**
```{r}
max(10,1/(1-summary(model3)$r.squared)) #threshold

vif(model3)
```
The VIF for both predicting variables is below the threshold value of 15.45466, so we can conclude that there is not colinearity between these predictors.

**(b) Conduct residual analysis for model3 (similar to Q4). Comment on each assumption and whether they hold.**
```{r}
res <- resid(model3)

ggplot(fish2, aes(x=Total.Length, y=res))+
         geom_point()+
         geom_smooth(method=loess)

plot(model3, which = c(1:2),  col ="blue")

hist(model3$residuals, col ="blue")

```
Residual vs. Total.Length plot: This plot has a U-shaped fit suggesting the linearity assumption does not hold.  

Residuals vs Fitted Values Plot: The constant variance assumption does not appear to hold.  The variance appears to increase as th response variable increases.

QQ Plot:A heavy right tail suggests the normality assumption does not hold.

Histogram of Residuals: The distribution of residuals is still right skewed in this model, confirming the normality assumption has been violated as shown in the QQ plot.

# Question 7: Transformation [9 pts]

**(a) Use model3 to find the optimal lambda, rounded to the nearest 0.5, for a Box-Cox transformation on model3.  What transformation, if any, should be applied according to the lambda value?  Please ensure you use model3**

```{r}
library(forecast)
boxCox(model3)
lambda <- BoxCox.lambda(fish2$Weight)
rounded <- ceiling(lambda*2) / 2
print(paste("Rounded Optimal Lamda = ", rounded))
```

Per the Box-Cox table of common transformations a lamda value of .5 calls for a square root transformation fo the response variable.

**(b) Based on the results in (a), create model4 with the appropriate transformation. Display the summary.**
```{r}
fish2$sqrt_weight <- fish2$Weight^.5

model4 <- lm(sqrt_weight ~ Species + Total.Length, data = fish2)
summary(model4)
```


**(c) Perform Residual Analysis on model4. Comment on each assumption.  Was the transformation successful/unsuccessful?**
```{r}
res <- resid(model4)

ggplot(fish2, aes(x=Total.Length, y=res))+
         geom_point()+
         geom_smooth(method=loess)

plot(model4, which = c(1:2),  col ="blue")

hist(model4$residuals, col ="blue")

```
Residual vs. Total.Length plot: The distribution of residuals seems to be more random now.  There is not a clear shape to the trend.  Residuals appear t be eaqually above and belwo the zero line, suggesting the linearity assumption holds. 

Residuals vs Fitted Values Plot: The constant variance assumption does appear to hold since the residuals appear to be randomly distributed about the 0-line aver all values of the fitted response variable. There is no strong, pattern, clusters.

QQ Plot:The right tail has been greatly reduced by this transformation and the normality assumption now seems to hold.

Histogram of Residuals: The residuals now appear normally distributed suggesting the normality assumption has been satisfied. 

# Question 8: Model Comparison [2 pts]

**(a) Using each model summary, compare and discuss the R-squared and Adjusted R-squared of model2, model3, and model4.**

```{r}


r_table <- data.frame(Model = c("Model2", "Model3", "Model4"),
                      R2 = c(summary(model2)$r.squared,
                             summary(model3)$r.squared,
                             summary(model4)$r.squared),
                      Adj_R2 = c(summary(model2)$adj.r.squared,
                                 summary(model3)$adj.r.squared,
                                 summary(model4)$adj.r.squared))
r_table
```
Model 4 is the best model in terms of r-squared.  Both adjusted r-squared and r-squared are highest for the transformed model4. 

# Question 9: Prediction [8 points]

**(a) Predict Weight for the last 10 rows of data (fishtest) using both model3 and model4.  Compare and discuss the mean squared prediction error (MSPE) of both models.** 

```{r}
pred3 <- predict(model3, fishtest)
pred4 <- predict(model4, fishtest)^2 #squaring to transform response back to orginal scale

pred_table <- data.frame(pred3, pred4, fishtest$Weight)
                         
MSPE_table <- data.frame(Model = c("Model3", "Model4"),
                         MSPE = c(mean((fishtest$Weight - pred3)^2),
                                  mean((fishtest$Weight - pred4)^2)))
pred_table
MSPE_table
```
Model4 much more accurately predicts the response value, Weight which is why is has a significantly smaller MSPE.  Model4 is the best model that has been created in the scope of this assignment.

**(b) Suppose you have found a Perch fish with a Body.Height of 28 cm, and a Total.Length of 32 cm. Using model4, predict the weight on this fish with a 90% prediction interval.  Provide an interpretation of the prediction interval.**

```{r}
test_point <- data.frame(Body.Height = 28, Total.Length = 32, Species = "Perch")

predict(model4, test_point, interval = "prediction", level = .9)^2
```

Model4 predicts the weight of this Perch to be 374.4536g. At a 90% level of accuarcy, the weight of the Perch will be between 361.9429g and 558.6091g.

