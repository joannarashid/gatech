---
title: "HW1 Peer Assessment"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Part A. ANOVA

Additional Material: ANOVA tutorial

https://datascienceplus.com/one-way-anova-in-r/

Jet lag is a common problem for people traveling across multiple time zones, but people can gradually adjust to the new time zone since the exposure of the shifted light schedule to their eyes can resets the internal circadian rhythm in a process called “phase shift”. Campbell and Murphy (1998) in a highly controversial study reported that the human circadian clock can also be reset by only exposing the back of the knee to light, with some hailing this as a major discovery and others challenging aspects of the experimental design. The table below is taken from a later experiment by Wright and Czeisler (2002) that re-examined the phenomenon. The new experiment measured circadian rhythm through the daily cycle of melatonin production in 22 subjects randomly assigned to one of three light treatments. Subjects were woken from sleep and for three hours were exposed to bright lights applied to the eyes only, to the knees only or to neither (control group). The effects of treatment to the circadian rhythm were measured two days later by the magnitude of phase shift (measured in hours) in each subject’s daily cycle of melatonin production. A negative measurement indicates a delay in melatonin production, a predicted effect of light treatment, while a positive number indicates an advance.

Raw data of phase shift, in hours, for the circadian rhythm experiment

|Treatment|Phase Shift (hr)                            |
|:--------|:-------------------------------------------|
|Control  |0.53, 0.36, 0.20, -0.37, -0.60, -0.64, -0.68, -1.27|
|Knees    |0.73, 0.31, 0.03, -0.29, -0.56, -0.96, -1.61       |
|Eyes     |-0.78, -0.86, -1.35, -1.48, -1.52, -2.04, -2.83    |

## Question A1 - 3 pts

Consider the following incomplete R output:

|Source|Df |Sum of Squares|Mean Squares|F-statistics|p-value|
|:----:|:-:|:------------:|:----------:|:----------:|:-----:|
|Treatments|?|?|3.6122|?|0.004|
|Error|?|9.415|?| | |
|TOTAL|?|?| | | |

Fill in the missing values in the analysis of the variance table.Note: Missing values can be calculated using the corresponding formulas provided in the lectures, or you can build the data frame in R and generate the ANOVA table using the aov() function. Either approach will be accepted.

**Creating data frame:**
```{r}
Control  <- c(0.53, 0.36, 0.20, -0.37, -0.60, -0.64, -0.68, -1.27)
Knees    <- c(0.73, 0.31, 0.03, -0.29, -0.56, -0.96, -1.61)
Eyes     <- c(-0.78, -0.86, -1.35, -1.48, -1.52, -2.04, -2.83)

df <- data.frame(Treatment = character(), Phase_Shift = numeric())

for (i in Control){
  df <- rbind(df, c('Control', i))
}

for (i in Knees){
  df <- rbind(df, c('Knees', i))
}

for (i in Eyes){
  df <- rbind(df, c('Eyes', i))
}

colnames(df) = c('Treatment', 'Phase_Shift') #correcting column names

df$Phase_Shift <- as.numeric(df$Phase_Shift) #changing Phase_Shift values to numeric

```

**Checking for outliers:**
```{r}
library(ggplot2)

ggplot(df, aes(Phase_Shift, Treatment))+
  geom_boxplot(aes(col=Treatment))+
  labs(title="Boxplot of Treatments")
```

**ANOVA model:**
```{r}
aov_model <- aov(Phase_Shift~ Treatment,
                 data = df)
summary(aov_model)
```

## Question A2 - 3 pts

Use $\mu_1$, $\mu_2$, and $\mu_3$  as notation for the three mean parameters and define these parameters clearly based on the context of the topic above  (i.e. explain what  $\mu_1$, $\mu_2$, and $\mu_3$ mean in words in the context of this problem). Find the estimates of these parameters.

```{r}
model.tables(aov_model, type = "means")
```

**Mean phase-shift values for each treatment in experiment:**

 $\mu_1= -0.3087$  **This value represents the mean of the 'Control' treatment values.**
 
 $\mu_2= -1.551$  **This value represents the mean of the 'Knees' treatment values.**
 
 $\mu_3= -0.3357$  **This value represents the mean of the 'Eyes' treatment values.**

## Question A3 - 5 pts

Use the ANOVA table in Question A1 to answer the following questions:

a. **1 pts** Write the null hypothesis of the ANOVA $F$-test, 

$H_0  \mu_1 = \mu_2 = \mu_3$

b. **1 pts** Write the alternative hypothesis of the ANOVA $F$-test, 

$H_A \mu_1 \neq \mu_2$ or $H_A \mu_2 \neq \mu_3$ 
**Essentially the alternative hypothesis is that the mean of at least two treatment groups are not equal.**

c. **1 pts** Fill in the blanks for the degrees of freedom of the ANOVA $F$-test statistic:   

$F$**(2, 19)**

d. **1 pts** What is the p-value of the ANOVA $F$-test? 

**0.00447**

e. **1 pts** According the the results of the ANOVA $F$-test, does light treatment affect phase shift?  Use an $\alpha$-level of 0.05.

**Since the p-value of this f-test is .00447 at a 99.9% level of significance, we can conclude that there is a statistically significant difference in means between treatment groups at a 95% level of significance as well.**

# Part B. Simple Linear Regression

We are going to use regression analysis to estimate the performance of CPUs based on the maximum number of channels in the CPU.  This data set comes from the UCI Machine Learning Repository.

The data file includes the following columns:

* *vendor*: vendor of the CPU
* *chmax*: maximum channels in the CPU
* *performance*: published relative performance of the CPU

The data is in the file "machine.csv". To read the data in `R`, save the file in your working directory (make sure you have changed the directory if different from the R working directory) and read the data using the `R` function `read.csv()`.

```{r}
# Read in the data
data = read.csv("machine.csv", head = TRUE, sep = ",")
# Show the first few rows of data
head(data, 3)
```

## Question B1: Exploratory Data Analysis - 9 pts

a. **3 pts** Use a scatter plot to describe the relationship between CPU performance and the maximum number of channels. Describe the general trend (direction and form). Include plots and R-code used.

```{r}
library(ggplot2)

ggplot(data, 
       aes(x = chmax, 
           y = performance,
           color = vendor)) +
           geom_point()+
           geom_smooth(method=lm , color="grey", se=FALSE)
```

b. **3 pts** What is the value of the correlation coefficient between _performance_ and _chmax_? Please interpret the strength of the correlation based on the correlation coefficient.

```{r}
cor.test(data$performance, data$chmax)
```
**The coefficient for maximum number of channels is .6052093.  Each additional channel a CPU has will result in a .6052093 increase in performance.**

c. **2 pts** Based on this exploratory analysis, would you recommend a simple linear regression model for the relationship?

**It seems the two variables are positively correlated in a linear fashion.  However, transformations of the variables are likely necessary since the variance does not appear to be constant.**

d. **1 pts** Based on the analysis above, would you pursue a transformation of the data? *Do not transform the data.*  Possibly depending on diagnostics from the initial linear model.

```{r}
hist(data$performance)
```


**Yes, it looks as though a log transformation is necessary since the variance is increasing as the value of 'chmax' increases.  Additionally, the histogram of the response variable above shows a skewed right rather than normal distribution.**

## Question B2: Fitting the Simple Linear Regression Model - 11 pts

Fit a linear regression model, named *model1*, to evaluate the relationship between performance and the maximum number of channels. *Do not transform the data.* The function you should use in R is:

```{r}
model1 = lm(performance ~ chmax, data)

summary(model1)
```

a. **3 pts** What are the model parameters and what are their estimates?  

$\beta_{0} = 37.2252$ and $\beta_{1} = 3.7441$

b. **2 pts** Write down the estimated simple linear regression equation.

$CPU performance = 37.2252 + 3.7441 chmax + \epsilon$

c. **2 pts** Interpret the estimated value of the $\beta_1$ parameter in the context of the problem.

**The estimator for** $\beta_1$ **estimates that each additional channel will result in an increase of 3.7441 units in performance.**

d. **2 pts** Find a 95% confidence interval for the $\beta_1$ parameter. Is $\beta_1$ statistically significant at this level? 
```{r}
confint(model1, 
        'chmax', 
        level = .95 )
```
**A 95% confidence interval for** $\beta_1$ **is (3.069251,4.4189260).**  $\beta_1$ **is statistically significant at this level of confidence since the p-value is extremely low (< 2e-16 even at 99.9% significance).**

e. **2 pts** Is $\beta_1$ statistically significantly positive at an $\alpha$-level of 0.01?  What is the approximate p-value of this test?

```{r}
confint(model1, 
        'chmax', 
        level = .99 )
```

**The value of the estimator for** $\beta_1$ **is a positive at a significance level of 99% as it demonstrated by the confidence level above.  Given that that p-value for this estimator is as close to 0 as R can report at a 9.99% level of significance, we can conclude with nearly 100% certainly that the estimator for** $\beta_1$ **is positive.**

## Question B3: Checking the Assumptions of the Model - 8 pts

Create and interpret the following graphs with respect to the assumptions of the linear regression model. In other words, comment on whether there are any apparent departures from the assumptions of the linear regression model. Make sure that you state the model assumptions and assess each one.  Each graph may be used to assess one or more model assumptions.

a. **2 pts** Scatterplot of the data with *chmax* on the x-axis and *performance* on the y-axis

```{r}
ggplot(data, 
       aes(x = chmax, 
           y = performance)) +
           geom_point()+
           geom_smooth(method=lm , color="grey", se=FALSE)
```

**Model Assumption(s) it checks: Constant Variance Assumption**

**Interpretation: This simple scatter plot checks the constant variance assumption. This plot shows that the variance is not constant, but increases with the value of 'chmax.' The constant variance assumption does not hold.**

b. **3 pts** Residual plot - a plot of the residuals, $\hat\epsilon_i$, versus the fitted values, $\hat{y}_i$

```{r}
plot(model1, which=1:1)
```

**Model Assumption(s) it checks: Independence Assumption**

**Interpretation: The fitted values vs. residual plot shows heteroskedasticity, meaning that the variance is not constant and the independence assumption does not hold.**

c. **3 pts** Histogram and q-q plot of the residuals

```{r}
library(car)

plot(model1, which=2:2)

hist(model1$residuals)

```

**Model Assumption(s) it checks: Normality Assumption**

**Interpretation: The histogram of residuals indicates the the residuals are somewhat normally distrusted, but the residuals on the q-q plot do not align with the line suggesting the normality assumption does not hold.**


## Question B4: Improving the Fit - 10 pts

a. **2 pts** Use a Box-Cox transformation (`boxCox()`) in `car()` package or (`boxcox()`) in `MASS()` package to find the optimal $\lambda$ value rounded to the nearest half integer.  What transformation of the response, if any, does it suggest to perform?

```{r}
boxCox(model1)
```
**It looks like the best**$\lambda$**value is very close to 0.  Which means a log-transformation is appropriate for this model.**

b. **2 pts** Create a linear regression model, named *model2*, that uses the log transformed *performance* as the response, and the log transformed *chmax* as the predictor. Note: The variable *chmax* has a couple of zero values which will cause problems when taking the natural log. Please add one to the predictor before taking the natural log of it

```{r}
data$log_chmax <- log(data$chmax+1) #creating log of chmax
data$log_performance <- log(data$performance+1) #creating log of performance

model2 = lm(log_performance ~ log_chmax, data)

summary(model2)
```

c. **2 pts** Compare the R-squared values of *model1* and *model2*.  Did the transformation improve the explanatory power of the model?

**Model 1 (linear model)** $R^{2} = 0.3663$

**Model 2 (linear model with log transofrmation)** $R^{2} = 0.407$

**This log transformation improved the R-squared value and is therefore a better model.**

d. **4 pts** Similar to Question B3, assess and interpret all model assumptions of *model2*.  A model is considered a good fit if all assumptions hold. Based on your interpretation of the model assumptions, is *model2* a good fit?

```{r}
ggplot(data, 
       aes(x = log_chmax, 
           y = log_performance)) +
           geom_point()+
           geom_smooth(method=lm , color="grey", se=FALSE)
```
**The scatter plot above shows that the log-transformed model is better.  The variance appears to be approximately constant, so the constant variance assumption holds.**
```{r}
plot(model2, which=1:1)
```
**The fitted values vs. residual plot shows no heteroskedasticity and the independence assumption holds.**

```{r}
plot(model2, which=2:2)

hist(model2$residuals)
```
**The histogram of residuals indicates the the residuals are normally distributed. The residuals on the q-q plot align with the line, suggesting the normality assumption holds.**

**In summary, diagnostics of residuals on model2 satisfy all of the model assumptions, indicating log-transformed model is a good fit for this data.**

## Question B5: Prediction - 3 pts

Suppose we are interested in predicting CPU performance when `chmax = 128`. Please make a prediction using both *model1* and *model2* and provide the 95% prediction interval of each prediction on the original scale of the response, *performance*. What observations can you make about the result in the context of the problem?

```{r}
#calculate predictions
model1_predict <- predict(model1, data.frame(chmax = 128), interval = "predict",level=0.95)
model2_predict <- predict(model2, data.frame(log_chmax = log(128)), interval = "predict",level=0.95)
```
**Model 1 prediction for chmax = 128:**
```{r}
model1_predict
```
**Model 2 (log-transformed) prediction for chmax = 128:**
```{r}
#converting back to orginal scale
undo_log <- function(x){exp(x)}
apply(model2_predict,c(1), undo_log)
```
**The predicted performance value for 'chmax' = 128 is 516.4685 for model 1 and 274.70172 for the log transformed model 2.  The value for model 2 seems more realistic given the linear trend of this data, but it is notable the the confidence interval for model 2 more than twice as large.**

# Part C. ANOVA - 8 pts

We are going to continue using the CPU data set to analyse various vendors in the data set.  There are over 20 vendors in the data set.  To simplify the task, we are going to limit our analysis to three vendors, specifically, honeywell, hp, and nas.  The code to filter for those vendors is provided below.

```{r}
# Filter for honeywell, hp, and nas
data2 = data[data$vendor %in% c("honeywell", "hp", "nas"), ]
data2$vendor = factor(data2$vendor)
```

1. **2 pts** Using `data2`, create a boxplot of *performance* and *vendor*, with *performance* on the vertical axis.  Interpret the plots.  

```{r}
ggplot(data2, aes(performance, vendor))+
  geom_boxplot(aes(col=vendor))+
  labs(title="Boxplot of Performance by Vendor")
```
**At first glance, HP and NAS have very different means, though Honeywell and HP are similar. All three groups have markedly different within-group variability.**

2. **3 pts** Perform an ANOVA F-test on the means of the three vendors.  Using an $\alpha$-level of 0.05, can we reject the null hypothesis that the means of the three vendors are equal?  Please interpret.

```{r}
aov_model2 <- aov(performance~ vendor,
                 data = data2)
summary(aov_model2)
```
**A at 95% level of significance (**$\alpha=.05$**), we can reject the null hypothesis that the means of these groups are equal. A high f-value of 6.027 with a p-value of .00553 at a 99.9% level of significance indicates there is little chance of the null hypothesis being true.**

3. **3 pts** Perform a Tukey pairwise comparison between the three vendors. Using an $\alpha$-level of 0.05, which means are statistically significantly different from each other?

```{r}
TukeyHSD(aov_model2)
```
**The Pairwise Tukey analysis above indicates that, an $\alpha$-level of 0.05 or 95% level of significance, NAS and Honeywell are different from one another as are NAS and HP.  However, we cannot reject the null hypothesis that the means of HP and Honeywell are equal to 0.**